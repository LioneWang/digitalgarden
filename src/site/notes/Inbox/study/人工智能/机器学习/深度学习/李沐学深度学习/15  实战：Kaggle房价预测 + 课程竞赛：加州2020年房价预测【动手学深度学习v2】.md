---
{"dg-publish":true,"tags":["deep_learning","course"],"permalink":"/Inbox/study/人工智能/机器学习/深度学习/李沐学深度学习/15  实战：Kaggle房价预测 + 课程竞赛：加州2020年房价预测【动手学深度学习v2】/","dgPassFrontmatter":true}
---



# 15  实战：Kaggle房价预测 + 课程竞赛：加州2020年房价预测【动手学深度学习v2】
- 环境
	- 虚拟环境名字：regression
	- python版本：3.9
	- cuda版本：11.6
- 过程
	- 数据获取：通过爬虫拿到数据，分成训练集和测试集 [1.2 数据获取](1.2%20数据获取.md)
	- 数据清洗：
		- 连续值：归一化处理+缺失值置0[2.2 数据清洗](2.2%20数据清洗.md)[10.1 深度神经网络架构](10.1%20深度神经网络架构.md)
		- 离散值：用one-hot编码表示特征(0/1),因此特征维度会增加[2.4 特征工程](2.4%20特征工程.md)
	- 选择模型，损失函数和优化器，超参数进行训练：
		- 模型：输出是标量，用线性模型[3.3 线性模型](3.3%20线性模型.md)
		- 损失函数：
			- 回归任务，用MSE[3.3 线性模型](3.3%20线性模型.md)
			- 分类任务，用交叉熵函数[3.3 线性模型](3.3%20线性模型.md)
		- 优化器：
			- 用了Adam（对学习率不太敏感）
			- SGD[3.4 随机梯度下降](3.4%20随机梯度下降.md)
		- 超参数：k折，batch_size，learning rate，weight decay，epoch数
		- 输出信息：每轮epoch，用优化器优化后的权重和完整的训练数据集，重新放入net中计算损失函数
	- 评估指标：
		- 回归任务误差率通常用：真实值-预测值；但是这个任务着重于比较两者之间的差异，所以用log的减法来做[3.3 线性模型](3.3%20线性模型.md)
		- 分类任务的指标通常不太一样，有BLEU，XCOMET等
	- 验证
		- 选择K折交叉验证
	- 预测
		- 超参数：通过调节超参数，观察评估指标（损失函数）的大小，找到最优的超参数组合
		- 将这些超参数作为初始超参数重新训练训练集，收敛后net保留最优的模型权重
		- 把测试集的输入特征输入到这个net中得到预测结果
---
# References
[4.10. 实战Kaggle比赛：预测房价 — 动手学深度学习 2.0.0 documentation](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html)
