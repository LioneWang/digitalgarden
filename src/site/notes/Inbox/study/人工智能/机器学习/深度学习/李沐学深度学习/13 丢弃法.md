---
{"dg-publish":true,"tags":["deep_learning","course"],"permalink":"/Inbox/study/人工智能/机器学习/深度学习/李沐学深度学习/13 丢弃法/","dgPassFrontmatter":true}
---



# 13 丢弃法
- 目的：对输入数据加入扰动的鲁棒，增加泛化能力
- 实现
	![tmp-88.png](/img/user/Assets/attachments/tmp/tmp-88.png)
	- 主要作用于隐藏层的输出
	![tmp-89.png](/img/user/Assets/attachments/tmp/tmp-89.png)
	- 注意：[[Inbox/wiki/dropout\|dropout]]只用在训练中，因为目的是改变模型权重；推理时不需要用到，因为模型权重已经确定了
- 总结
	- dropout的做法等价于让某些子神经网络的权重变成0，其实也是[[Inbox/wiki/正则化\|正则化]]处理的一种，相当于让模型权重减少到0
	- 丢弃的概率p是超参数

---
# References
[13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Y5411c7aY/?spm_id_from=333.1387.collection.video_card.click&vd_source=73a67190a2e14f51c71c0fa447f094aa)