---
{"dg-publish":true,"tags":["deep_learning","cnn"],"permalink":"/Inbox/study/人工智能/机器学习/深度学习/李沐学深度学习/19 卷积层/","dgPassFrontmatter":true}
---




# 19 卷积层
- 和Mlp的区别：
	- 用MLP处理12M像素相机拍摄的图片，一共三个通道共36M像素，输入层有36M的输入，假设隐藏层有100个输出，那么需要3.6B的元素，内存根本存不下
- 分类器找图片的原则
	- 平移不变性：原本情况下，如果输入是二维输出也是二维，权重应该是四维的；但是平移不变性指出无论图片中要识别的模式在上下左右哪一个位置，分类器都应该是一样的，因此虽然权重仍然是四维的，但等价为二维交叉相关。（等价于降低权重的复杂度）
	- 局部性：对于每一个输入的像素点，只需要提取周围部分区域的特征即可；所以权重矩阵的范围应该比较小（等价于降低全连接层的输出大小）
- 总结
	- 卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出
	- 核矩阵和偏移都是可以学习的参数
	- 核矩阵的大小是超参数
	

---
# References
https://www.bilibili.com/video/BV1L64y1m7Nh/?spm_id_from=333.1387.collection.video_card.click&vd_source=73a67190a2e14f51c71c0fa447f094aa