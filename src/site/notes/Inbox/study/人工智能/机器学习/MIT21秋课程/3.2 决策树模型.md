---
{"dg-publish":true,"tags":["MIT","course","deep_learning","machine_learning"],"permalink":"/Inbox/study/人工智能/机器学习/MIT21秋课程/3.2 决策树模型/","dgPassFrontmatter":true}
---



# 3.2 决策树模型
- 决策树
	- 分类树：叶节点是类别
	- 回归树：叶节点是值
- 优点：
	- 可解释
	- 可以处理分类和回归两种情况
- 缺点：
	- 非常不稳定
		- 解决办法：
			-  随机森林：训练很多的决策树来提高稳定性（并行）[5.2 Bagging](5.2%20Bagging.md)
			- 基于梯度的boosting：训练n颗树，每次训练的树结合前面训练的所有结果（类似残差网络）（串行）[5.3 Boosting](5.3%20Boosting.md)
	- 复杂树会过拟合

---
# References
[3.2 最简单也最常用的决策树【斯坦福21秋季：实用机器学习中文版】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV17u411f7dt?spm_id_from=333.788.videopod.sections&vd_source=73a67190a2e14f51c71c0fa447f094aa)