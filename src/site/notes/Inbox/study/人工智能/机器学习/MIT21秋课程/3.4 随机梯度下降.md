---
{"dg-publish":true,"tags":["MIT","course","deep_learning","machine_learning"],"permalink":"/Inbox/study/人工智能/机器学习/MIT21秋课程/3.4 随机梯度下降/","dgPassFrontmatter":true}
---


# 3.4 随机梯度下降
- w是模型参数，b是batch size，n是学习率
- 首先随机化模型参数
- 迭代次数取决于epoch，每次迭代取b个样本更新模型参数
    - 回归：直接mse更新权重
    - 分类：每个样本的交叉熵损失函数求均值然后更新权重
![tmp-33.png](/img/user/Assets/attachments/tmp/tmp-33.png)
---
# References
[3.4 随机梯度下降【斯坦福21秋季：实用机器学习中文版】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1234y1m75j?spm_id_from=333.788.videopod.sections&vd_source=73a67190a2e14f51c71c0fa447f094aa)