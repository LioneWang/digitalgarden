---
{"dg-publish":true,"tags":["MIT","deep_learning","machine_learning","course"],"permalink":"/Inbox/study/人工智能/机器学习/MIT21秋课程/5.4 Stacking/","dgPassFrontmatter":true}
---




- 将各种模型结合起来降低方差
	- 基础模型可以是不同的模型类别
	- 每个模型的输出concat起来然后通过一个全连接层学习权重
- stacking和bagging的区别：
	- bagging的模型都是相同的，数据不同；而stacking的数据是相同的（不用bootstrap），模型是不同的
![tmp-48.png](/img/user/Assets/attachments/tmp/tmp-48.png)
![tmp-49.png](/img/user/Assets/attachments/tmp/tmp-49.png)
- 第0个模型就是所有模型做stacking的结果
- 多层stacking
![tmp-50.png](/img/user/Assets/attachments/tmp/tmp-50.png)

---
# References
[5.4 Stacking【斯坦福21秋季：实用机器学习中文版】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1PZ4y197CX?spm_id_from=333.788.player.switch&vd_source=73a67190a2e14f51c71c0fa447f094aa)